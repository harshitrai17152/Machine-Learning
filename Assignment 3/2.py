# -*- coding: utf-8 -*-
"""question_2.ipynb

Automatically generated by Colaboratory.

# References
"""

# https://medium.com/ml2vec/intro-to-pytorch-with-image-classification-on-a-fashion-clothes-dataset-e589682df0c5
# https://www.arunprakash.org/2018/12/cnn-fashion-mnist-dataset-pytorch.html

"""# Initilizing"""

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix
from torch.autograd import Variable
from torchvision import transforms
from torchvision import datasets
import torch.nn.functional as F
import matplotlib.pyplot as plt
import torch.optim as optim 
from sklearn import svm
import torch.nn as nn
import torchvision
import numpy as np
import torch

# Commented out IPython magic to ensure Python compatibility.
#from __future__ import absolute_import, division, print_function, unicode_literals
#try:
#   %tensorflow_version 2.x
#except Exception:
#  pass
  
#import tensorflow_datasets as tfds
#import tensorflow as tf
#tf.test.gpu_device_name()

"""# CNN Class"""

class CNN(nn.Module):
  
  def __init__(self,classes):
    self.classes=classes
    self.fully_connected=0
    
    super(CNN,self).__init__()
    
    self.hidden_layer=nn.Sequential(
      nn.Conv2d(1,20,kernel_size=(3,3),stride=1),
      nn.ReLU(),
      nn.MaxPool2d(kernel_size=(3,3),stride=2))
  
    self.fc_layer=nn.Linear(12*12*20,self.classes)

  def forward(self,X):
    out1=self.hidden_layer(X)
    out2=out1.reshape(out1.size(0),-1)
    out3=self.fc_layer(out2)
    self.fully_connected=out3
    
    return(out3)

"""# Loading the Data"""

tr=transforms.Compose([transforms.ToTensor()])
batch_size=100
epochs=10
features=728 #(28,28)
classes=10

training=datasets.FashionMNIST('~/.pytorch/F_MNIST_data/',download=True,train=True,transform=tr)
train=torch.utils.data.DataLoader(training,batch_size=batch_size,shuffle=True)

testing=datasets.FashionMNIST('~/datasets/F_MNIST/',download=True,train=False,transform=tr)
test=torch.utils.data.DataLoader(testing,batch_size=batch_size,shuffle=True)

"""# Main"""

model=CNN(classes)
criterion=nn.CrossEntropyLoss()
optimizer=optim.Adam(model.parameters(),lr=0.001)

train_losses=[]
test_losses=[]

for e in range(epochs):
  
  train_loss=0
  test_loss=0
  train_acc=0
  test_acc=0
  
  # For Test Set
  for images,labels in train:
      optimizer.zero_grad() # For starting the iteration from 0
      
      log_ps1=model(images)  # Output from CNN
      prob=torch.exp(log_ps1)
      top_probs,top_classes=prob.topk(1,dim=1)
      equals=labels==top_classes.view(labels.shape)
      train_acc=train_acc+equals.type(torch.FloatTensor).mean()
      
      loss=criterion(model(images),labels)
      train_loss=train_loss+loss.item()
      loss.backward()
      optimizer.step()
     
  else:
    # For Train Set
    with torch.no_grad():
          model.eval()
          for images,labels in test:
              log_ps2=model(images)
              prob=torch.exp(log_ps2)
              top_probs,top_classes=prob.topk(1,dim=1)
              equals=labels==top_classes.view(labels.shape)
              test_acc=test_acc+equals.type(torch.FloatTensor).mean()
              test_loss=(test_loss+criterion(log_ps2,labels)).item()
    model.train()
        
  print("Accuracy on Train Set:",((train_acc*100)/len(train)).item())
  train_loss=train_loss/len(train)
  train_losses.append(train_loss)
  
  print("Accuracy on Test Set:",((test_acc*100)/len(test)).item())
  test_loss=test_loss/len(test)
  test_losses.append(test_loss)
  print()

def plotting(rmse_5_folds_train,itr):
    lin=[i+1 for i in range(itr)]
    plt.plot(lin,rmse_5_folds_train[0],'r')
    plt.plot(lin,rmse_5_folds_train[1],'b')
    plt.plot(lin,rmse_5_folds_train[2],'g')
    plt.plot(lin,rmse_5_folds_train[3],'c')
    plt.plot(lin,rmse_5_folds_train[4],'y')
    plt.gca().legend(('Fold 1','Fold 2','Fold 3','Fold 4','Fold 5'))
    plt.xlabel('Number of iterations')
    plt.ylabel('RMSE')
    plt.title('RMSE vs Iterations (Training Set)')
    plt.show()

"""# Plot"""

plt.plot(train_losses,label="Train losses")
plt.title("loss-per-epoch for Train Set")

plt.plot(test_losses,label="Test losses")
plt.title("loss-per-epoch for Test Set")

"""# Kernelized SVM"""

# For Testing Set

X_test=[]
Y_test=[]

for images,labels in test:
  images=Variable(images.float())
  outputs=model(images)
 
  X_test.extend(np.array(outputs.data))
  Y_test.extend(np.array(labels))

clf=svm.SVC(kernel='rbf',gamma='scale',probability=True)
clf.fit(X_test,Y_test)
print("Accuracy of SVM Kernelized CNN on testing Set:",clf.score(X_test,Y_test)*100)

p=clf.predict(X_test)
confusion_matrix(Y_test,p)

# For Training Set

X_train=[]
Y_train=[]

for images,labels in train:
  images=Variable(images.float())
  outputs=model(images)
  X_train.extend(np.array(outputs.data))
  Y_train.extend(np.array(labels))

clf=svm.SVC(kernel='rbf',gamma='scale',probability=True)
clf.fit(X_train,Y_train)
print("Accuracy of SVM Kernelized CNN on training Set:",clf.score(X_train,Y_train)*100)

p=clf.predict(X_train)
confusion_matrix(Y_train,p)
